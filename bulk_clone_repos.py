#!/usr/bin/env python3
import os
import sys
import json
import time
import subprocess
import requests
import re
from datetime import datetime

# --- C·∫§U H√åNH ---
class Config:
    REPO_LIST_FILE = "README.txt"
    CLONE_DIR = "community-templates"
    TOP_N_REPOS = 50
    MARKDOWN_RESULT_FILE = "filtered.md"
    API_CACHE_FILE = "api_cache.json"
    GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")
    # Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc repo (t√≠nh b·∫±ng KB). 5MB = 5 * 1024 = 5120 KB
    MAX_REPO_SIZE_KB = 5120

# --- C√ÅC H√ÄM LOGIC ---

def parse_markdown_for_repos(md_file):
    """ƒê·ªçc file markdown k·∫øt qu·∫£ v√† tr√≠ch xu·∫•t danh s√°ch URL repo."""
    print(f"üìÑ T√¨m th·∫•y file '{md_file}'. ƒêang s·ª≠ d·ª•ng danh s√°ch repo t·ª´ file n√†y...")
    repos = []
    try:
        with open(md_file, 'r') as f:
            for line in f:
                match = re.search(r"\[(https://github.com/.+?)\]", line)
                if match:
                    repos.append({"url": match.group(1)})
    except FileNotFoundError:
        return []
    
    if not repos:
        print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t repo n√†o t·ª´ '{md_file}'. S·∫Ω ti·∫øn h√†nh g·ªçi API.", file=sys.stderr)
    return repos

def get_top_repos_from_api(config):
    """
    L·∫•y danh s√°ch repo h√†ng ƒë·∫ßu b·∫±ng c√°ch g·ªçi API, l·ªçc theo k√≠ch th∆∞·ªõc, s·ª≠ d·ª•ng cache v√† x·ª≠ l√Ω rate limit.
    """
    print("üîé Kh√¥ng t√¨m th·∫•y file k·∫øt qu·∫£. B·∫Øt ƒë·∫ßu qu√° tr√¨nh l·∫•y d·ªØ li·ªáu t·ª´ API GitHub...")
    
    cache = _load_cache(config.API_CACHE_FILE)
    
    try:
        with open(config.REPO_LIST_FILE, 'r') as f:
            urls = list(set(line.strip() for line in f if "github.com" in line.strip()))
    except FileNotFoundError:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{config.REPO_LIST_FILE}'.", file=sys.stderr)
        sys.exit(1)

    all_repos_data = []
    for url in urls:
        repo_info = _fetch_repo_metadata(url, cache, config)
        if repo_info:
            all_repos_data.append(repo_info)
    
    _save_cache(config.API_CACHE_FILE, cache)
    
    all_repos_data.sort(key=lambda x: x['stars'], reverse=True)
    top_repos = all_repos_data[:config.TOP_N_REPOS]
    
    _write_markdown_file(config.MARKDOWN_RESULT_FILE, top_repos)
    return top_repos

def clone_or_update_repos(config, repos_to_process):
    """Clone ho·∫∑c c·∫≠p nh·∫≠t c√°c kho ch·ª©a ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh."""
    if not repos_to_process:
        print("ü§∑ Kh√¥ng c√≥ kho ch·ª©a n√†o ƒë·ªÉ x·ª≠ l√Ω. D·ª´ng l·∫°i.")
        return
        
    print(f"\nüöÄ S·∫Ω ti·∫øn h√†nh clone/c·∫≠p nh·∫≠t {len(repos_to_process)} kho ch·ª©a...")
    os.makedirs(config.CLONE_DIR, exist_ok=True)
    
    for repo in repos_to_process:
        try:
            parts = repo['url'].strip("/").split('/')
            owner, repo_name = parts[-2], parts[-1].replace(".git", "")
            target_dir = os.path.join(config.CLONE_DIR, f"{owner}__{repo_name}".lower())

            if os.path.isdir(target_dir):
                print(f"üîÑ ƒêang c·∫≠p nh·∫≠t {repo_name}...")
                subprocess.run(["git", "-C", target_dir, "pull"], check=True, capture_output=True)
            else:
                stars_info = f"(‚≠ê {repo.get('stars', 'N/A')})" if 'stars' in repo else ""
                print(f"üì• ƒêang clone {repo_name} {stars_info}...")
                subprocess.run(["git", "clone", repo['url'], target_dir], check=True, capture_output=True)

        except (subprocess.CalledProcessError, IndexError, KeyError) as e:
            error_message = e.stderr.decode() if isinstance(e, subprocess.CalledProcessError) else str(e)
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω {repo.get('url', 'URL kh√¥ng x√°c ƒë·ªãnh')}: {error_message}", file=sys.stderr)

# --- C√ÅC H√ÄM H·ªñ TR·ª¢ (Private) ---

def _load_cache(cache_file):
    if os.path.exists(cache_file):
        with open(cache_file, 'r') as f:
            return json.load(f)
    return {}

def _save_cache(cache_file, cache_data):
    with open(cache_file, 'w') as f:
        json.dump(cache_data, f, indent=4)

def _fetch_repo_metadata(repo_url, cache, config):
    """H√†m l·∫•y metadata c·ªßa repo, bao g·ªìm c·∫£ ki·ªÉm tra k√≠ch th∆∞·ªõc."""
    if repo_url in cache and 'size' in cache[repo_url]: # Ki·ªÉm tra xem cache c≈© c√≥ 'size' kh√¥ng
        # N·∫øu repo trong cache ƒë√£ b·ªã l·ªçc v√¨ k√≠ch th∆∞·ªõc, th√¨ b·ªè qua lu√¥n
        if cache[repo_url] is None: return None
        # Ki·ªÉm tra l·∫°i size trong cache v·ªõi config hi·ªán t·∫°i
        if cache[repo_url]['size'] > config.MAX_REPO_SIZE_KB:
             print(f"üì¶ B·ªè qua t·ª´ cache (qu√° l·ªõn): {repo_url} ({cache[repo_url]['size']} KB)")
             return None
        print(f"üì¶ D√πng cache cho: {repo_url}")
        return cache[repo_url]

    api_url = f"https://api.github.com/repos/{'/'.join(repo_url.strip('/').split('/')[-2:]).replace('.git','')}"
    headers = {"Accept": "application/vnd.github.v3+json"}
    if config.GITHUB_TOKEN:
        headers["Authorization"] = f"token {config.GITHUB_TOKEN}"

    try:
        response = requests.get(api_url, headers=headers)
        if response.status_code in [404, 403, 451]: return None
        if response.status_code == 429 or ('X-RateLimit-Remaining' in response.headers and int(response.headers['X-RateLimit-Remaining']) == 0):
            reset_time = int(response.headers.get('X-RateLimit-Reset', time.time() + 60))
            wait_time = max(reset_time - time.time(), 0) + 1
            print(f"‚è≥ B·ªã gi·ªõi h·∫°n API. ƒêang ƒë·ª£i {int(wait_time)} gi√¢y...", file=sys.stderr)
            time.sleep(wait_time)
            return _fetch_repo_metadata(repo_url, cache, config) # Th·ª≠ l·∫°i
        
        response.raise_for_status()
        data = response.json()
        
        repo_size_kb = data.get("size", 0)
        # *** LOGIC L·ªåC K√çCH TH∆Ø·ªöC ***
        if repo_size_kb > config.MAX_REPO_SIZE_KB:
            print(f"üö´ B·ªè qua (qu√° l·ªõn): {repo_url} ({repo_size_kb} KB > {config.MAX_REPO_SIZE_KB} KB)")
            cache[repo_url] = None # L∆∞u "None" v√†o cache ƒë·ªÉ kh√¥ng g·ªçi l·∫°i repo n√†y
            return None

        result = {
            "url": repo_url, 
            "stars": data.get("stargazers_count", 0),
            "size": repo_size_kb
        }
        cache[repo_url] = result
        print(f"üìû L·∫•y t·ª´ API: {repo_url} - ‚≠ê {result['stars']} - {result['size']} KB")
        return result
    except requests.exceptions.RequestException:
        return None

def _write_markdown_file(md_file, repos):
    """Ghi k·∫øt qu·∫£ ra file markdown, th√™m c·ªôt k√≠ch th∆∞·ªõc."""
    with open(md_file, 'w') as f:
        f.write(f"# Top {len(repos)} Kho Ch·ª©a Git (Nh·ªè h∆°n {Config.MAX_REPO_SIZE_KB / 1024}MB)\n\n")
        f.write(f"*T·ª± ƒë·ªông t·∫°o l√∫c: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
        f.write("*X√≥a file n√†y ƒë·ªÉ bu·ªôc k·ªãch b·∫£n l·∫•y l·∫°i d·ªØ li·ªáu m·ªõi t·ª´ API.*\n\n")
        f.write("| H·∫°ng | T√™n Kho Ch·ª©a | ‚≠ê Sao | K√≠ch th∆∞·ªõc | URL |\n")
        f.write("|------|--------------|-------|------------|-----|\n")
        for i, repo in enumerate(repos, 1):
            owner, repo_name = repo['url'].strip("/").split('/')[-2:]
            repo_name = repo_name.replace('.git','')
            size_mb = f"{repo['size'] / 1024:.2f} MB"
            f.write(f"| {i} | `{owner}/{repo_name}` | {repo['stars']} | `{size_mb}` | [{repo['url']}]({repo['url']}) |\n")
    print(f"\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ x·∫øp h·∫°ng v√†o file: {md_file}")

# --- ƒêI·ªÇM KH·ªûI ƒê·ªòNG ---

def main():
    """H√†m ƒëi·ªÅu ph·ªëi ch√≠nh c·ªßa k·ªãch b·∫£n."""
    config = Config()
    
    # Logic kh√¥ng ƒë·ªïi: ∆∞u ti√™n d√πng markdown, n·∫øu kh√¥ng th√¨ g·ªçi API
    repos_to_process = parse_markdown_for_repos(config.MARKDOWN_RESULT_FILE)
    if not repos_to_process:
        repos_to_process = get_top_repos_from_api(config)
    
    clone_or_update_repos(config, repos_to_process)
    
    print("\nüéâ Ho√†n th√†nh!")

if __name__ == "__main__":
    main()
